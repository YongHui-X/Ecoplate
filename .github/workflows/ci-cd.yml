name: CI/CD

on:
  push:
    branches: [main, dev]
  pull_request:
    branches: [main, dev]

concurrency:
  group: cicd-${{ github.event_name == 'pull_request' && github.head_ref || github.ref }}
  cancel-in-progress: ${{ github.event_name == 'pull_request' }}

env:
  REGISTRY: ghcr.io
  APP_IMAGE: ghcr.io/gdipsa-team2/ecoplate-app
  REC_IMAGE: ghcr.io/gdipsa-team2/ecoplate-recommendation

jobs:
  # ===========================================================================
  # LAYER 0 ‚Äî Code Quality & Tests
  # ===========================================================================

  typecheck-backend:
    name: Typecheck Backend
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: oven-sh/setup-bun@v2
        with:
          bun-version: "1.3"
      - run: bun install --ignore-scripts
      - run: cd backend && bunx tsc --noEmit

  typecheck-frontend:
    name: Typecheck Frontend
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: oven-sh/setup-bun@v2
        with:
          bun-version: "1.3"
      - run: bun install --ignore-scripts
      - run: cd frontend && bunx tsc --noEmit

  test-backend:
    name: Test Backend
    runs-on: ubuntu-latest
    env:
      JWT_SECRET: ci-test-secret
    steps:
      - uses: actions/checkout@v4
      - uses: oven-sh/setup-bun@v2
        with:
          bun-version: "1.3"
      - run: bun install --ignore-scripts
      - name: Run backend tests with coverage
        run: cd backend && bun test --coverage --coverage-reporter=lcov --coverage-reporter=text --coverage-dir=coverage 2>&1 | tee test-output.txt
      - name: Write test summary
        if: always()
        run: |
          echo "## Backend Test Results" >> $GITHUB_STEP_SUMMARY
          # Extract Bun test summary (format: "323 pass")
          PASS=$(grep -E "^[[:space:]]*[0-9]+ pass" backend/test-output.txt | tail -1 || echo "")
          FAIL=$(grep -E "^[[:space:]]*[0-9]+ fail" backend/test-output.txt | tail -1 || echo "")
          echo "‚úÖ **$PASS** $FAIL" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          # Extract coverage table (Bun format: File | % Funcs | % Lines | Uncovered)
          echo "### Coverage" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          grep -E "(^-+\||File.*\||All files)" backend/test-output.txt | head -5 >> $GITHUB_STEP_SUMMARY || echo "See job logs for details"
          echo '```' >> $GITHUB_STEP_SUMMARY
      - name: Upload backend coverage
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backend-coverage
          path: backend/coverage/
          retention-days: 5

  test-frontend:
    name: Test Frontend
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: oven-sh/setup-bun@v2
        with:
          bun-version: "1.3"
      - run: bun install --ignore-scripts
      - name: Run frontend tests with coverage
        run: cd frontend && bun run test:coverage 2>&1 | tee test-output.txt
      - name: Write test summary
        if: always()
        run: |
          echo "## Frontend Test Results" >> $GITHUB_STEP_SUMMARY
          # Extract Vitest summary line (format: "Tests  547 passed | 30 skipped")
          SUMMARY=$(grep -E "Tests.*passed" frontend/test-output.txt | tail -1 | sed 's/\x1b\[[0-9;]*m//g' || echo "No results")
          echo "‚úÖ **$SUMMARY**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          # Extract coverage summary
          echo "### Coverage" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          # Get coverage summary section (last few lines with percentages)
          grep -E "^(Statements|Branches|Functions|Lines)\s*:" frontend/test-output.txt >> $GITHUB_STEP_SUMMARY || echo "See job logs for details"
          echo '```' >> $GITHUB_STEP_SUMMARY
      - name: Upload frontend coverage
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: frontend-coverage
          path: frontend/coverage/
          retention-days: 14

  test-recommendation:
    name: Test Recommendation Engine
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install dependencies
        run: |
          cd recommendation-engine
          pip install -r requirements.txt
          pip install pytest pytest-cov
      - name: Run tests with coverage
        run: |
          cd recommendation-engine
          pytest test_*.py -v \
            --cov=. --cov-report=term-missing \
            --cov-report=html:coverage-html \
            --cov-report=lcov:coverage.lcov \
            --junitxml=test-results.xml 2>&1 | tee test-output.txt
      - name: Write test summary
        if: always()
        run: |
          echo "## Recommendation Engine Test Results" >> $GITHUB_STEP_SUMMARY
          # Extract pytest summary (e.g., "X passed in Y seconds")
          SUMMARY=$(grep -E "passed|failed" recommendation-engine/test-output.txt | grep -E "^=.*=$" | tail -1 || echo "No results")
          echo "‚úÖ **$SUMMARY**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          # Extract coverage summary
          echo "### Coverage" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          grep -E "^(TOTAL|Name|--)" recommendation-engine/test-output.txt | head -10 >> $GITHUB_STEP_SUMMARY || echo "See job logs for details"
          echo '```' >> $GITHUB_STEP_SUMMARY
      - name: Upload recommendation coverage
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: recommendation-coverage
          path: |
            recommendation-engine/coverage-html/
            recommendation-engine/test-results.xml
            recommendation-engine/coverage.lcov
          retention-days: 14

  test-coverage-summary:
    name: Test Coverage Summary
    needs: [test-backend, test-frontend, test-recommendation]
    runs-on: ubuntu-latest
    if: always()
    permissions:
      pull-requests: write
    steps:
      - name: Install lcov
        run: sudo apt-get update && sudo apt-get install -y lcov

      - name: Download backend coverage
        uses: actions/download-artifact@v4
        with:
          name: backend-coverage
          path: backend-cov/
        continue-on-error: true

      - name: Download frontend coverage
        uses: actions/download-artifact@v4
        with:
          name: frontend-coverage
          path: frontend-cov/
        continue-on-error: true

      - name: Download recommendation coverage
        uses: actions/download-artifact@v4
        with:
          name: recommendation-coverage
          path: recommendation-cov/
        continue-on-error: true

      - name: Merge coverage and generate detailed HTML reports
        run: |
          mkdir -p combined-report/backend combined-report/frontend combined-report/recommendation

          # Collect available lcov files and generate detailed HTML
          LCOV_ARGS=""
          if [ -f backend-cov/lcov.info ]; then
            LCOV_ARGS="$LCOV_ARGS -a backend-cov/lcov.info"
            # Generate detailed HTML for backend using genhtml
            genhtml backend-cov/lcov.info -o combined-report/backend --title "Backend Coverage" --legend || true
          fi
          if [ -f frontend-cov/lcov.info ]; then
            LCOV_ARGS="$LCOV_ARGS -a frontend-cov/lcov.info"
            # Copy frontend Istanbul HTML report (already detailed with line-by-line)
            if [ -d frontend-cov ]; then
              cp -r frontend-cov/* combined-report/frontend/ 2>/dev/null || true
            fi
          fi
          if [ -f recommendation-cov/coverage.lcov ]; then
            LCOV_ARGS="$LCOV_ARGS -a recommendation-cov/coverage.lcov"
            # Copy recommendation pytest-cov HTML report
            if [ -d recommendation-cov/coverage-html ]; then
              cp -r recommendation-cov/coverage-html/* combined-report/recommendation/ 2>/dev/null || true
            fi
          fi

          # Generate merged lcov for PR annotations
          if [ -n "$LCOV_ARGS" ]; then
            lcov $LCOV_ARGS -o combined-report/lcov.info 2>/dev/null || true
          fi

      - name: Extract per-component coverage and generate dashboard
        id: coverage
        run: |
          extract_lcov_metric() {
            local file="$1" metric="$2"
            if [ -f "$file" ]; then
              local result
              result=$(lcov --summary "$file" 2>&1 | grep "$metric" | awk '{print $2}' | tr -d '%')
              if [ -z "$result" ] || echo "$result" | grep -qiE "^(no|n/a|nan)"; then
                echo "N/A"
              elif echo "$result" | grep -qE '^[0-9.]+$'; then
                echo "$result"
              else
                echo "N/A"
              fi
            else
              echo "N/A"
            fi
          }

          get_color() {
            val="$1"
            if [ "$val" = "N/A" ]; then echo "na"
            elif [ "$(echo "$val >= 70" | bc -l 2>/dev/null || echo 0)" = "1" ]; then echo "good"
            elif [ "$(echo "$val >= 50" | bc -l 2>/dev/null || echo 0)" = "1" ]; then echo "okay"
            else echo "poor"
            fi
          }

          # Extract metrics
          BE_LINES=$(extract_lcov_metric backend-cov/lcov.info "lines")
          BE_FUNCS=$(extract_lcov_metric backend-cov/lcov.info "functions")
          BE_BRANCH=$(extract_lcov_metric backend-cov/lcov.info "branches")
          FE_LINES=$(extract_lcov_metric frontend-cov/lcov.info "lines")
          FE_FUNCS=$(extract_lcov_metric frontend-cov/lcov.info "functions")
          FE_BRANCH=$(extract_lcov_metric frontend-cov/lcov.info "branches")
          RE_LINES=$(extract_lcov_metric recommendation-cov/coverage.lcov "lines")
          RE_FUNCS=$(extract_lcov_metric recommendation-cov/coverage.lcov "functions")
          RE_BRANCH=$(extract_lcov_metric recommendation-cov/coverage.lcov "branches")

          # Calculate averages
          AVG_LINES=$(python3 -c "vals=[float(v) for v in '${BE_LINES},${FE_LINES},${RE_LINES}'.split(',') if v.replace('.','',1).isdigit()]; print(f'{sum(vals)/len(vals):.1f}' if vals else 'N/A')")
          AVG_FUNCS=$(python3 -c "vals=[float(v) for v in '${BE_FUNCS},${FE_FUNCS},${RE_FUNCS}'.split(',') if v.replace('.','',1).isdigit()]; print(f'{sum(vals)/len(vals):.1f}' if vals else 'N/A')")
          AVG_BRANCH=$(python3 -c "vals=[float(v) for v in '${BE_BRANCH},${FE_BRANCH},${RE_BRANCH}'.split(',') if v.replace('.','',1).isdigit()]; print(f'{sum(vals)/len(vals):.1f}' if vals else 'N/A')")

          # File counts for each component
          BE_FILES=$(find combined-report/backend -name "*.html" 2>/dev/null | wc -l | tr -d ' ')
          FE_FILES=$(find combined-report/frontend -name "*.html" 2>/dev/null | wc -l | tr -d ' ')
          RE_FILES=$(find combined-report/recommendation -name "*.html" 2>/dev/null | wc -l | tr -d ' ')

          # GitHub Step Summary
          echo "## Test Coverage Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Component | Lines | Functions | Branches |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|-------|-----------|----------|" >> $GITHUB_STEP_SUMMARY
          echo "| Backend | ${BE_LINES}% | ${BE_FUNCS}% | ${BE_BRANCH}% |" >> $GITHUB_STEP_SUMMARY
          echo "| Frontend | ${FE_LINES}% | ${FE_FUNCS}% | ${FE_BRANCH}% |" >> $GITHUB_STEP_SUMMARY
          echo "| Recommendation Engine | ${RE_LINES}% | ${RE_FUNCS}% | ${RE_BRANCH}% |" >> $GITHUB_STEP_SUMMARY
          echo "| **Average** | **${AVG_LINES}%** | **${AVG_FUNCS}%** | **${AVG_BRANCH}%** |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "> Download **combined-coverage-report** artifact for detailed line-by-line coverage." >> $GITHUB_STEP_SUMMARY

          # Generate comprehensive HTML dashboard
          REPORT_DATE=$(date -u '+%Y-%m-%d %H:%M UTC')
          cat > combined-report/index.html << HTMLEOF
          <!DOCTYPE html>
          <html lang="en">
          <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>EcoPlate - Combined Coverage Report</title>
            <style>
              :root { --bg-primary: #0f172a; --bg-secondary: #1e293b; --bg-card: #334155; --text-primary: #f1f5f9; --text-secondary: #94a3b8; --accent: #3b82f6; --good: #22c55e; --okay: #eab308; --poor: #ef4444; --border: #475569; }
              * { box-sizing: border-box; margin: 0; padding: 0; }
              body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: var(--bg-primary); color: var(--text-primary); line-height: 1.6; min-height: 100vh; }
              .container { max-width: 1200px; margin: 0 auto; padding: 2rem; }
              header { margin-bottom: 2rem; }
              h1 { font-size: 2rem; font-weight: 700; margin-bottom: 0.5rem; }
              .subtitle { color: var(--text-secondary); font-size: 0.95rem; }
              .meta { display: flex; gap: 2rem; margin-top: 1rem; font-size: 0.85rem; color: var(--text-secondary); }
              .summary-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 1.5rem; margin-bottom: 2rem; }
              .summary-card { background: var(--bg-secondary); border-radius: 12px; padding: 1.5rem; border: 1px solid var(--border); }
              .summary-card h3 { font-size: 0.85rem; text-transform: uppercase; letter-spacing: 0.05em; color: var(--text-secondary); margin-bottom: 1rem; }
              .summary-value { font-size: 2.5rem; font-weight: 700; font-family: 'SF Mono', Monaco, monospace; }
              .summary-value.good { color: var(--good); }
              .summary-value.okay { color: var(--okay); }
              .summary-value.poor { color: var(--poor); }
              .summary-label { color: var(--text-secondary); font-size: 0.9rem; margin-top: 0.25rem; }
              .progress-bar { width: 100%; height: 6px; background: var(--bg-primary); border-radius: 3px; overflow: hidden; margin-top: 0.5rem; }
              .progress-fill { height: 100%; border-radius: 3px; }
              .progress-fill.good { background: var(--good); }
              .progress-fill.okay { background: var(--okay); }
              .progress-fill.poor { background: var(--poor); }
              .quick-links { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 1rem; margin-bottom: 2rem; }
              .quick-link { display: flex; align-items: center; gap: 1rem; padding: 1.25rem; background: var(--bg-secondary); border: 1px solid var(--border); border-radius: 10px; text-decoration: none; color: var(--text-primary); transition: all 0.2s ease; }
              .quick-link:hover { border-color: var(--accent); transform: translateY(-2px); }
              .quick-link-icon { width: 48px; height: 48px; border-radius: 10px; display: flex; align-items: center; justify-content: center; font-size: 1.5rem; }
              .quick-link-icon.backend { background: linear-gradient(135deg, #6366f1, #8b5cf6); }
              .quick-link-icon.frontend { background: linear-gradient(135deg, #3b82f6, #06b6d4); }
              .quick-link-icon.recommendation { background: linear-gradient(135deg, #22c55e, #10b981); }
              .quick-link-content h4 { font-size: 1rem; font-weight: 600; margin-bottom: 0.25rem; }
              .quick-link-content p { font-size: 0.85rem; color: var(--text-secondary); }
              .table-container { background: var(--bg-secondary); border-radius: 12px; border: 1px solid var(--border); overflow: hidden; margin-bottom: 2rem; }
              .table-header { padding: 1rem 1.5rem; border-bottom: 1px solid var(--border); }
              .table-header h2 { font-size: 1.1rem; font-weight: 600; }
              table { width: 100%; border-collapse: collapse; }
              th, td { padding: 1rem 1.5rem; text-align: left; }
              th { background: var(--bg-card); font-size: 0.75rem; text-transform: uppercase; letter-spacing: 0.05em; color: var(--text-secondary); font-weight: 600; }
              tr:not(:last-child) td { border-bottom: 1px solid var(--border); }
              tr:hover td { background: rgba(59, 130, 246, 0.05); }
              .metric { font-family: 'SF Mono', Monaco, monospace; font-size: 0.9rem; }
              .metric.good { color: var(--good); }
              .metric.okay { color: var(--okay); }
              .metric.poor { color: var(--poor); }
              .avg-row { background: var(--bg-card); font-weight: 600; }
              footer { text-align: center; padding: 2rem; color: var(--text-secondary); font-size: 0.85rem; border-top: 1px solid var(--border); margin-top: 2rem; }
            </style>
          </head>
          <body>
            <div class="container">
              <header>
                <h1>EcoPlate Coverage Report</h1>
                <p class="subtitle">Combined test coverage with detailed line-by-line analysis</p>
                <div class="meta"><span>Generated: ${REPORT_DATE}</span></div>
              </header>
              <div class="summary-grid">
                <div class="summary-card">
                  <h3>Average Line Coverage</h3>
                  <div class="summary-value $(get_color ${AVG_LINES})">${AVG_LINES}%</div>
                  <p class="summary-label">Across all components</p>
                  <div class="progress-bar"><div class="progress-fill $(get_color ${AVG_LINES})" style="width: ${AVG_LINES}%"></div></div>
                </div>
                <div class="summary-card">
                  <h3>Average Function Coverage</h3>
                  <div class="summary-value $(get_color ${AVG_FUNCS})">${AVG_FUNCS}%</div>
                  <p class="summary-label">Functions tested</p>
                  <div class="progress-bar"><div class="progress-fill $(get_color ${AVG_FUNCS})" style="width: ${AVG_FUNCS}%"></div></div>
                </div>
                <div class="summary-card">
                  <h3>Average Branch Coverage</h3>
                  <div class="summary-value $(get_color ${AVG_BRANCH})">${AVG_BRANCH}%</div>
                  <p class="summary-label">Decision branches tested</p>
                  <div class="progress-bar"><div class="progress-fill $(get_color ${AVG_BRANCH})" style="width: ${AVG_BRANCH}%"></div></div>
                </div>
              </div>
              <h2 style="font-size: 1.25rem; margin-bottom: 1rem;">Detailed Reports (Click to View Line-by-Line Coverage)</h2>
              <div class="quick-links">
                <a href="backend/index.html" class="quick-link">
                  <div class="quick-link-icon backend">‚öôÔ∏è</div>
                  <div class="quick-link-content"><h4>Backend Coverage</h4><p>Bun API server ‚Ä¢ ${BE_LINES}% lines ‚Ä¢ ${BE_FILES} files</p></div>
                </a>
                <a href="frontend/index.html" class="quick-link">
                  <div class="quick-link-icon frontend">üñ•Ô∏è</div>
                  <div class="quick-link-content"><h4>Frontend Coverage</h4><p>React + Capacitor ‚Ä¢ ${FE_LINES}% lines ‚Ä¢ ${FE_FILES} files</p></div>
                </a>
                <a href="recommendation/index.html" class="quick-link">
                  <div class="quick-link-icon recommendation">ü§ñ</div>
                  <div class="quick-link-content"><h4>Recommendation Engine</h4><p>Python Flask ML API ‚Ä¢ ${RE_LINES}% lines ‚Ä¢ ${RE_FILES} files</p></div>
                </a>
              </div>
              <div class="table-container">
                <div class="table-header"><h2>Coverage by Component</h2></div>
                <table>
                  <thead><tr><th>Component</th><th>Lines</th><th>Functions</th><th>Branches</th><th>Detailed Report</th></tr></thead>
                  <tbody>
                    <tr><td>Backend (Bun)</td><td class="metric $(get_color ${BE_LINES})">${BE_LINES}%</td><td class="metric $(get_color ${BE_FUNCS})">${BE_FUNCS}%</td><td class="metric $(get_color ${BE_BRANCH})">${BE_BRANCH}%</td><td><a href="backend/index.html" style="color: var(--accent);">View Details ‚Üí</a></td></tr>
                    <tr><td>Frontend (React)</td><td class="metric $(get_color ${FE_LINES})">${FE_LINES}%</td><td class="metric $(get_color ${FE_FUNCS})">${FE_FUNCS}%</td><td class="metric $(get_color ${FE_BRANCH})">${FE_BRANCH}%</td><td><a href="frontend/index.html" style="color: var(--accent);">View Details ‚Üí</a></td></tr>
                    <tr><td>Recommendation Engine (Python)</td><td class="metric $(get_color ${RE_LINES})">${RE_LINES}%</td><td class="metric $(get_color ${RE_FUNCS})">${RE_FUNCS}%</td><td class="metric $(get_color ${RE_BRANCH})">${RE_BRANCH}%</td><td><a href="recommendation/index.html" style="color: var(--accent);">View Details ‚Üí</a></td></tr>
                    <tr class="avg-row"><td>Average</td><td class="metric">${AVG_LINES}%</td><td class="metric">${AVG_FUNCS}%</td><td class="metric">${AVG_BRANCH}%</td><td></td></tr>
                  </tbody>
                </table>
              </div>
              <footer>
                <p>Generated by EcoPlate CI/CD Pipeline</p>
                <p style="margin-top: 0.5rem;">Thresholds: <span style="color: var(--good);">‚â•70% Good</span> ‚Ä¢ <span style="color: var(--okay);">‚â•50% Okay</span> ‚Ä¢ <span style="color: var(--poor);">&lt;50% Needs Work</span></p>
              </footer>
            </div>
          </body>
          </html>
          HTMLEOF

      - name: Annotate PR with coverage
        if: github.event_name == 'pull_request' && hashFiles('combined-report/lcov.info') != ''
        uses: zgosalvez/github-actions-report-lcov@v4
        with:
          coverage-files: combined-report/lcov.info
          minimum-coverage: 60
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload combined coverage report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: combined-coverage-report
          path: combined-report/
          retention-days: 14

  build-check:
    name: Build Frontend
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: oven-sh/setup-bun@v2
        with:
          bun-version: "1.3"
      - run: bun install --ignore-scripts
      - run: cd frontend && bun run build

  # ===========================================================================
  # LAYER 0 ‚Äî Security Scanning (parallel with tests)
  # ===========================================================================

  semgrep:
    name: SAST (Semgrep)
    runs-on: ubuntu-latest
    container:
      image: semgrep/semgrep
    steps:
      - uses: actions/checkout@v4

      - name: Run Semgrep
        run: |
          semgrep scan --config=auto \
            --exclude "security" \
            --exclude-rule "javascript.express.security.x-frame-options-misconfiguration.x-frame-options-misconfiguration" \
            --exclude-rule "javascript.lang.security.audit.unsafe-formatstring.unsafe-formatstring" \
            --exclude-rule "generic.nginx.security.header-redefinition.header-redefinition" \
            --exclude-rule "generic.nginx.security.possible-h2c-smuggling.possible-nginx-h2c-smuggling" \
            --exclude-rule "python.flask.security.audit.hardcoded-config.avoid_hardcoded_config_TESTING" \
            --exclude-rule "yaml.github-actions.security.workflow-run-target-code-checkout.workflow-run-target-code-checkout" \
            --json --output=semgrep-report.json . || true
          semgrep scan --config=auto \
            --exclude "security" \
            --exclude-rule "javascript.express.security.x-frame-options-misconfiguration.x-frame-options-misconfiguration" \
            --exclude-rule "javascript.lang.security.audit.unsafe-formatstring.unsafe-formatstring" \
            --exclude-rule "generic.nginx.security.header-redefinition.header-redefinition" \
            --exclude-rule "generic.nginx.security.possible-h2c-smuggling.possible-nginx-h2c-smuggling" \
            --exclude-rule "python.flask.security.audit.hardcoded-config.avoid_hardcoded_config_TESTING" \
            --exclude-rule "yaml.github-actions.security.workflow-run-target-code-checkout.workflow-run-target-code-checkout" \
            . || true

      - name: Upload Semgrep report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: semgrep-report
          path: semgrep-report.json
          retention-days: 30
          if-no-files-found: ignore

  python-sast:
    name: Python SAST (Bandit)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install Bandit
        run: pip install bandit[toml] || true

      - name: Run Bandit
        run: |
          bandit -r recommendation-engine/ \
            -x recommendation-engine/test_app.py \
            -f json -o bandit-report.json \
            --severity-level medium || true

      - name: Display Bandit results
        if: always()
        run: |
          bandit -r recommendation-engine/ \
            -x recommendation-engine/test_app.py \
            --severity-level medium || true

      - name: Upload Bandit report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: bandit-report
          path: bandit-report.json
          retention-days: 30
          if-no-files-found: ignore

  secret-scan:
    name: Secret Scanning (Trufflehog)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install Trufflehog
        run: |
          curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin

      - name: Run Trufflehog
        run: |
          trufflehog git file://. --only-verified --json > trufflehog-report.json 2>trufflehog-stderr.log || true
          echo "=== Secret Scan Results ==="
          trufflehog git file://. --only-verified || true

      - name: Upload report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trufflehog-report
          path: |
            trufflehog-report.json
            trufflehog-stderr.log
          retention-days: 30
          if-no-files-found: ignore

  python-deps:
    name: Python SCA (pip-audit)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install pip-audit
        run: pip install pip-audit || true

      - name: Run pip-audit
        run: |
          pip-audit -r recommendation-engine/requirements.txt \
            -f json -o pip-audit-report.json || true

      - name: Display results
        if: always()
        run: pip-audit -r recommendation-engine/requirements.txt || true

      - name: Upload report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pip-audit-report
          path: pip-audit-report.json
          retention-days: 30
          if-no-files-found: ignore

  js-deps:
    name: JS SCA (npm audit)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Audit backend dependencies
        run: |
          cd backend
          npm install --package-lock-only --ignore-scripts 2>/dev/null || true
          echo "=== Backend npm audit (production only) ==="
          npm audit --omit=dev --json > ../backend-audit.json 2>&1 || true
          npm audit --omit=dev || true
        continue-on-error: true

      - name: Audit frontend dependencies
        run: |
          cd frontend
          npm install --package-lock-only --ignore-scripts 2>/dev/null || true
          echo "=== Frontend npm audit (production only) ==="
          npm audit --omit=dev --json > ../frontend-audit.json 2>&1 || true
          npm audit --omit=dev || true
        continue-on-error: true

      - name: Upload audit reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: js-audit-reports
          path: |
            backend-audit.json
            frontend-audit.json
          retention-days: 30
          if-no-files-found: ignore

  iac-scan:
    name: IaC Scanning (Checkov)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run Checkov
        uses: bridgecrewio/checkov-action@v12
        with:
          directory: .
          framework: dockerfile
          output_format: cli,json
          output_file_path: console,checkov-results.json
          soft_fail: true

      - name: Upload Checkov report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: checkov-report
          path: checkov-results.json
          retention-days: 30
          if-no-files-found: ignore

  license-check:
    name: License Compliance
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Check Python licenses
        run: |
          pip install pip-licenses || true
          pip install -r recommendation-engine/requirements.txt || true
          echo "=== Python License Report ==="
          pip-licenses --format=markdown --with-urls | tee python-licenses.md
          echo ""
          echo "=== Checking for problematic licenses ==="
          pip-licenses --fail-on="GPL;AGPL" || echo "Warning: GPL/AGPL licenses detected"

      - name: Upload license report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: license-report
          path: python-licenses.md
          retention-days: 30
          if-no-files-found: ignore

  sbom:
    name: Generate SBOM
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Syft
        run: |
          curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin || true

      - name: Generate SBOM for repository
        run: |
          syft dir:. -o spdx-json=sbom-repo.spdx.json || true
          syft dir:. -o cyclonedx-json=sbom-repo.cdx.json || true

      - name: Upload SBOM
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sbom
          path: |
            sbom-repo.spdx.json
            sbom-repo.cdx.json
          retention-days: 90
          if-no-files-found: ignore

  # ===========================================================================
  # LAYER 1 ‚Äî CI Gate
  # ===========================================================================

  ci-gate:
    name: CI Gate
    needs:
      - typecheck-backend
      - typecheck-frontend
      - test-backend
      - test-frontend
      - test-recommendation
      - build-check
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Check CI results
        run: |
          echo "=== CI Gate Summary ==="
          echo "Typecheck Backend: ${{ needs.typecheck-backend.result }}"
          echo "Typecheck Frontend: ${{ needs.typecheck-frontend.result }}"
          echo "Test Backend: ${{ needs.test-backend.result }}"
          echo "Test Frontend: ${{ needs.test-frontend.result }}"
          echo "Test Recommendation: ${{ needs.test-recommendation.result }}"
          echo "Build Check: ${{ needs.build-check.result }}"

          if [ "${{ needs.typecheck-backend.result }}" != "success" ] || \
             [ "${{ needs.typecheck-frontend.result }}" != "success" ] || \
             [ "${{ needs.test-backend.result }}" != "success" ] || \
             [ "${{ needs.test-frontend.result }}" != "success" ] || \
             [ "${{ needs.test-recommendation.result }}" != "success" ] || \
             [ "${{ needs.build-check.result }}" != "success" ]; then
            echo "CI gate FAILED ‚Äî one or more jobs did not succeed"
            exit 1
          fi

          echo "CI gate passed"

  # ===========================================================================
  # LAYER 2 ‚Äî Determine Environment (push only)
  # ===========================================================================

  set-env:
    name: Set Environment
    needs: [ci-gate]
    if: github.event_name == 'push' && needs.ci-gate.result == 'success'
    runs-on: ubuntu-latest
    outputs:
      deploy_env: ${{ steps.env.outputs.deploy_env }}
    steps:
      - name: Determine deployment environment
        id: env
        run: |
          REF="${{ github.ref }}"
          if [ "$REF" == "refs/heads/main" ]; then
            echo "deploy_env=production" >> $GITHUB_OUTPUT
          elif [ "$REF" == "refs/heads/dev" ]; then
            echo "deploy_env=staging" >> $GITHUB_OUTPUT
          fi
          echo "Ref: $REF"

  # ===========================================================================
  # LAYER 3 ‚Äî Build & Push Container Images (push only)
  # ===========================================================================

  build-and-push:
    name: Build & Push Images
    needs: [set-env]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    outputs:
      app-digest: ${{ steps.build-app.outputs.digest }}
      rec-digest: ${{ steps.build-rec.outputs.digest }}
      image-tag: ${{ github.sha }}
    steps:
      - uses: actions/checkout@v4

      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Determine image tags
        id: tags
        run: |
          SHA="${{ github.sha }}"
          REF="${{ github.ref }}"
          if [ "$REF" == "refs/heads/main" ]; then
            echo "app_tags=${{ env.APP_IMAGE }}:${SHA},${{ env.APP_IMAGE }}:latest" >> $GITHUB_OUTPUT
            echo "rec_tags=${{ env.REC_IMAGE }}:${SHA},${{ env.REC_IMAGE }}:latest" >> $GITHUB_OUTPUT
          else
            echo "app_tags=${{ env.APP_IMAGE }}:${SHA},${{ env.APP_IMAGE }}:dev" >> $GITHUB_OUTPUT
            echo "rec_tags=${{ env.REC_IMAGE }}:${SHA},${{ env.REC_IMAGE }}:dev" >> $GITHUB_OUTPUT
          fi

      - name: Build & push app image
        id: build-app
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ${{ steps.tags.outputs.app_tags }}
          build-args: |
            VITE_GOOGLE_MAPS_API_KEY=${{ secrets.VITE_GOOGLE_MAPS_API_KEY }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build & push recommendation image
        id: build-rec
        uses: docker/build-push-action@v6
        with:
          context: ./recommendation-engine
          file: ./recommendation-engine/Dockerfile
          push: true
          tags: ${{ steps.tags.outputs.rec_tags }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # ===========================================================================
  # LAYER 4 ‚Äî Container Security Scanning (push only, parallel)
  # ===========================================================================

  scan-app-image:
    name: Scan App Image (Trivy)
    needs: [build-and-push]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: read
      security-events: write
    steps:
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull app image
        run: docker pull ${{ env.APP_IMAGE }}:${{ github.sha }}

      - name: Scan app image for vulnerabilities
        uses: aquasecurity/trivy-action@0.28.0
        with:
          image-ref: ${{ env.APP_IMAGE }}:${{ github.sha }}
          format: "table"
          output: "trivy-app-vuln.txt"
          severity: "HIGH,CRITICAL"
          exit-code: 0
          ignore-unfixed: true
        continue-on-error: true

      - name: Scan app image (SARIF)
        uses: aquasecurity/trivy-action@0.28.0
        with:
          image-ref: ${{ env.APP_IMAGE }}:${{ github.sha }}
          format: "sarif"
          output: "trivy-app.sarif"
          severity: "HIGH,CRITICAL"
        continue-on-error: true

      - name: Upload SARIF to GitHub Security
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: trivy-app.sarif
        continue-on-error: true

      - name: Upload vulnerability report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trivy-app-report
          path: trivy-app-vuln.txt
          retention-days: 30
          if-no-files-found: ignore

  scan-rec-image:
    name: Scan Recommendation Image (Trivy)
    needs: [build-and-push]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: read
      security-events: write
    steps:
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull recommendation image
        run: docker pull ${{ env.REC_IMAGE }}:${{ github.sha }}

      - name: Scan recommendation image for vulnerabilities
        uses: aquasecurity/trivy-action@0.28.0
        with:
          image-ref: ${{ env.REC_IMAGE }}:${{ github.sha }}
          format: "table"
          output: "trivy-rec-vuln.txt"
          severity: "HIGH,CRITICAL"
          exit-code: 0
          ignore-unfixed: true
        continue-on-error: true

      - name: Scan recommendation image (SARIF)
        uses: aquasecurity/trivy-action@0.28.0
        with:
          image-ref: ${{ env.REC_IMAGE }}:${{ github.sha }}
          format: "sarif"
          output: "trivy-rec.sarif"
          severity: "HIGH,CRITICAL"
        continue-on-error: true

      - name: Upload SARIF to GitHub Security
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: trivy-rec.sarif
        continue-on-error: true

      - name: Upload vulnerability report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trivy-rec-report
          path: trivy-rec-vuln.txt
          retention-days: 30
          if-no-files-found: ignore

  container-sbom:
    name: Generate Container SBOM
    needs: [build-and-push]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: read
    steps:
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Install Syft
        run: |
          curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin || true

      - name: Generate SBOM for app image
        run: |
          syft ${{ env.APP_IMAGE }}:${{ github.sha }} \
            -o spdx-json=sbom-app.spdx.json \
            -o cyclonedx-json=sbom-app.cdx.json || true

      - name: Generate SBOM for recommendation image
        run: |
          syft ${{ env.REC_IMAGE }}:${{ github.sha }} \
            -o spdx-json=sbom-rec.spdx.json \
            -o cyclonedx-json=sbom-rec.cdx.json || true

      - name: Upload Container SBOMs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: container-sbom
          path: |
            sbom-app.spdx.json
            sbom-app.cdx.json
            sbom-rec.spdx.json
            sbom-rec.cdx.json
          retention-days: 90
          if-no-files-found: ignore

  # ===========================================================================
  # LAYER 5 ‚Äî Deploy (push only, NO always())
  # ===========================================================================

  deploy-staging:
    name: Deploy to Staging
    needs: [build-and-push, set-env, scan-app-image, scan-rec-image]
    if: needs.set-env.outputs.deploy_env == 'staging'
    runs-on: ubuntu-latest
    environment: staging
    steps:
      - uses: actions/checkout@v4

      - name: Copy deploy files to Staging
        uses: appleboy/scp-action@v0.1.7
        with:
          host: ${{ secrets.EC2_DEV_HOST }}
          username: ${{ secrets.EC2_DEV_USER }}
          key: ${{ secrets.EC2_DEV_SSH_KEY }}
          source: "deploy/*"
          target: /ecoplate/
          strip_components: 0

      - name: Deploy via SSH
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.EC2_DEV_HOST }}
          username: ${{ secrets.EC2_DEV_USER }}
          key: ${{ secrets.EC2_DEV_SSH_KEY }}
          script: |
            echo "${{ secrets.GHCR_DEPLOY_TOKEN }}" | docker login ghcr.io -u "${{ secrets.GHCR_DEPLOY_USER }}" --password-stdin
            cd /ecoplate
            printf 'JWT_SECRET="%s"\nOPENAI_API_KEY="%s"\n' "$(echo '${{ secrets.JWT_SECRET }}' | tr -d '\n')" '${{ secrets.OPENAI_API_KEY }}' > deploy/.env
            chmod 600 deploy/.env
            export IMAGE_TAG="${{ github.sha }}"
            export APP_IMAGE="${{ env.APP_IMAGE }}"
            export REC_IMAGE="${{ env.REC_IMAGE }}"
            bash deploy/deploy.sh

  deploy-production:
    name: Deploy to Production
    needs: [build-and-push, set-env, scan-app-image, scan-rec-image]
    if: needs.set-env.outputs.deploy_env == 'production'
    runs-on: ubuntu-latest
    environment: production
    steps:
      - uses: actions/checkout@v4

      - name: Copy deploy files to Production
        uses: appleboy/scp-action@v0.1.7
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          source: "deploy/*"
          target: /ecoplate/
          strip_components: 0

      - name: Deploy via SSH
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            echo "${{ secrets.GHCR_DEPLOY_TOKEN }}" | docker login ghcr.io -u "${{ secrets.GHCR_DEPLOY_USER }}" --password-stdin
            cd /ecoplate
            printf 'JWT_SECRET="%s"\nOPENAI_API_KEY="%s"\n' "$(echo '${{ secrets.JWT_SECRET }}' | tr -d '\n')" '${{ secrets.OPENAI_API_KEY }}' > deploy/.env
            chmod 600 deploy/.env
            export IMAGE_TAG="${{ github.sha }}"
            export APP_IMAGE="${{ env.APP_IMAGE }}"
            export REC_IMAGE="${{ env.REC_IMAGE }}"
            bash deploy/deploy.sh

  # ===========================================================================
  # LAYER 6 ‚Äî DAST (push only)
  # ===========================================================================

  dast-zap:
    name: DAST - OWASP ZAP Full Scan
    needs: [deploy-staging, deploy-production]
    if: always() && (needs.deploy-staging.result == 'success' || needs.deploy-production.result == 'success')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Determine target host
        id: target
        run: |
          if [ "${{ needs.deploy-staging.result }}" == "success" ]; then
            echo "host=${{ secrets.EC2_DEV_HOST }}" >> $GITHUB_OUTPUT
            echo "env=staging" >> $GITHUB_OUTPUT
          else
            echo "host=${{ secrets.EC2_HOST }}" >> $GITHUB_OUTPUT
            echo "env=production" >> $GITHUB_OUTPUT
          fi

      - name: Wait for deployment to stabilize
        run: |
          echo "Target: ${{ steps.target.outputs.env }} (${{ steps.target.outputs.host }})"
          echo "Waiting 30 seconds for deployment to stabilize..."
          sleep 30
          for i in $(seq 1 10); do
            if curl -sfk https://${{ steps.target.outputs.host }}/api/v1/health > /dev/null 2>&1; then
              echo "Application is healthy"
              break
            fi
            echo "Attempt $i/10 - waiting..."
            sleep 10
          done

      - name: Run ZAP Full Scan
        uses: zaproxy/action-full-scan@v0.13.0
        with:
          target: "https://${{ steps.target.outputs.host }}"
          cmd_options: "-a -j"
          allow_issue_writing: false
          artifact_name: zap-full-report
        continue-on-error: true

  dast-api:
    name: DAST - API Security Scan
    needs: [deploy-staging, deploy-production]
    if: always() && (needs.deploy-staging.result == 'success' || needs.deploy-production.result == 'success')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Determine target host
        id: target
        run: |
          if [ "${{ needs.deploy-staging.result }}" == "success" ]; then
            echo "host=${{ secrets.EC2_DEV_HOST }}" >> $GITHUB_OUTPUT
            echo "env=staging" >> $GITHUB_OUTPUT
          else
            echo "host=${{ secrets.EC2_HOST }}" >> $GITHUB_OUTPUT
            echo "env=production" >> $GITHUB_OUTPUT
          fi

      - name: Wait for deployment
        run: |
          sleep 45
          curl -sfk https://${{ steps.target.outputs.host }}/api/v1/health || true

      - name: Run ZAP API Scan
        uses: zaproxy/action-api-scan@v0.9.0
        with:
          target: "https://${{ steps.target.outputs.host }}/api/v1/"
          format: openapi
          cmd_options: "-a"
          allow_issue_writing: false
          artifact_name: zap-api-report
        continue-on-error: true

  # ===========================================================================
  # LAYER 6.5 ‚Äî E2E Functional Tests (push only)
  # ===========================================================================

  e2e-tests:
    name: E2E Selenium Tests
    needs: [deploy-staging, deploy-production]
    if: always() && (needs.deploy-staging.result == 'success' || needs.deploy-production.result == 'success')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Setup Firefox
        uses: browser-actions/setup-firefox@v1
        with:
          firefox-version: latest

      - name: Setup GeckoDriver
        uses: browser-actions/setup-geckodriver@latest

      - name: Verify browser versions
        run: |
          firefox --version
          geckodriver --version

      - name: Determine target host
        id: target
        run: |
          if [ "${{ needs.deploy-staging.result }}" == "success" ]; then
            echo "host=${{ secrets.EC2_DEV_HOST }}" >> $GITHUB_OUTPUT
            echo "env=staging" >> $GITHUB_OUTPUT
          else
            echo "host=${{ secrets.EC2_HOST }}" >> $GITHUB_OUTPUT
            echo "env=production" >> $GITHUB_OUTPUT
          fi

      - name: Wait for deployment to stabilize
        run: |
          echo "Target: ${{ steps.target.outputs.env }} (${{ steps.target.outputs.host }})"
          echo "Waiting for deployment to stabilize..."
          sleep 30
          for i in $(seq 1 10); do
            if curl -sfk https://${{ steps.target.outputs.host }}/api/v1/health > /dev/null 2>&1; then
              echo "Application is healthy"
              break
            fi
            echo "Attempt $i/10 - waiting..."
            sleep 10
          done

      - name: Install E2E dependencies
        run: |
          cd e2e
          npm install
          mkdir -p reports screenshots

      - name: Run E2E tests
        id: e2e
        run: |
          cd e2e
          npm test 2>&1 | tee test-output.log
          TEST_EXIT_CODE=${PIPESTATUS[0]}
          if [ $TEST_EXIT_CODE -ne 0 ]; then
            echo "e2e_failed=true" >> $GITHUB_OUTPUT
          fi
          exit 0
        env:
          HEADLESS: "true"
          BROWSER: "firefox"
          BASE_URL: https://${{ steps.target.outputs.host }}
          NODE_TLS_REJECT_UNAUTHORIZED: "0"
        continue-on-error: true

      - name: Generate fallback report if missing
        if: always()
        run: |
          if [ ! -f e2e/reports/test-report.html ]; then
            echo "Creating fallback report..."
            mkdir -p e2e/reports
            echo '<!DOCTYPE html><html><head><title>E2E Test Report</title></head><body><h1>E2E Test Report</h1><p>0 tests passed, 1 tests failed</p><p class="failed">Test execution failed - see workflow logs for details</p></body></html>' > e2e/reports/test-report.html
          fi

      - name: Write E2E test summary
        if: always()
        run: |
          echo "## E2E Selenium Test Results" >> $GITHUB_STEP_SUMMARY
          if [ -f e2e/test-output.log ]; then
            # Extract pass/fail counts
            PASSED=$(grep -c "‚úì\|PASSED\|passed" e2e/test-output.log 2>/dev/null || echo "0")
            FAILED=$(grep -c "‚úó\|FAILED\|failed" e2e/test-output.log 2>/dev/null || echo "0")
            echo "‚úÖ **$PASSED passed, $FAILED failed**" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è No test output available" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload test screenshots
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-screenshots
          path: e2e/screenshots/
          retention-days: 7
          if-no-files-found: ignore

      - name: Upload test report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-report
          path: e2e/reports/test-report.html
          retention-days: 30
          if-no-files-found: ignore

  # ===========================================================================
  # LAYER 7 ‚Äî Security Report (push only)
  # ===========================================================================

  security-report:
    name: Generate Security Report
    needs:
      - semgrep
      - python-sast
      - secret-scan
      - python-deps
      - js-deps
      - iac-scan
      - license-check
      - sbom
      - scan-app-image
      - scan-rec-image
      - container-sbom
      - dast-zap
      - dast-api
      - e2e-tests
    if: always() && github.event_name == 'push'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Download Semgrep report
        uses: actions/download-artifact@v4
        with: { name: semgrep-report, path: reports/semgrep }
        continue-on-error: true

      - name: Download Bandit report
        uses: actions/download-artifact@v4
        with: { name: bandit-report, path: reports/bandit }
        continue-on-error: true

      - name: Download Trufflehog report
        uses: actions/download-artifact@v4
        with: { name: trufflehog-report, path: reports/trufflehog }
        continue-on-error: true

      - name: Download pip-audit report
        uses: actions/download-artifact@v4
        with: { name: pip-audit-report, path: reports/pip-audit }
        continue-on-error: true

      - name: Download JS audit reports
        uses: actions/download-artifact@v4
        with: { name: js-audit-reports, path: reports/js-audit }
        continue-on-error: true

      - name: Download Checkov report
        uses: actions/download-artifact@v4
        with: { name: checkov-report, path: reports/checkov }
        continue-on-error: true

      - name: Download License report
        uses: actions/download-artifact@v4
        with: { name: license-report, path: reports/license }
        continue-on-error: true

      - name: Download SBOM
        uses: actions/download-artifact@v4
        with: { name: sbom, path: reports/sbom }
        continue-on-error: true

      - name: Download Trivy app report
        uses: actions/download-artifact@v4
        with: { name: trivy-app-report, path: reports/trivy-app }
        continue-on-error: true

      - name: Download Trivy rec report
        uses: actions/download-artifact@v4
        with: { name: trivy-rec-report, path: reports/trivy-rec }
        continue-on-error: true

      - name: Download Container SBOM
        uses: actions/download-artifact@v4
        with: { name: container-sbom, path: reports/container-sbom }
        continue-on-error: true

      - name: Download ZAP Full Scan report
        uses: actions/download-artifact@v4
        with: { name: zap-full-report, path: reports/zap-full }
        continue-on-error: true

      - name: Download ZAP API report
        uses: actions/download-artifact@v4
        with: { name: zap-api-report, path: reports/zap-api }
        continue-on-error: true

      - name: Download E2E test report
        uses: actions/download-artifact@v4
        with: { name: e2e-test-report, path: reports/e2e-test-report }
        continue-on-error: true

      - name: Download previous baseline for comparison
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: ci-cd.yml
          branch: ${{ github.ref_name }}
          name: security-baseline
          path: baseline/
          if_no_artifact_found: warn
          search_artifacts: true
        continue-on-error: true

      - name: Check report completeness
        run: |
          EXPECTED="semgrep bandit trufflehog pip-audit js-audit checkov license sbom trivy-app trivy-rec container-sbom zap-full zap-api e2e-test-report"
          SKIPPED=0
          for dir in $EXPECTED; do
            if [ -z "$(ls -A reports/$dir 2>/dev/null)" ]; then
              echo "::warning::Scan '$dir' produced no artifacts"
              SKIPPED=$((SKIPPED + 1))
            fi
          done
          echo "Skipped scans: $SKIPPED / 14"

      - name: Generate consolidated security report
        run: |
          BASELINE_ARG=""
          if [ -f baseline/security-baseline.json ]; then
            echo "Found previous baseline - will generate comparison"
            BASELINE_ARG="--baseline baseline/security-baseline.json"
          else
            echo "No previous baseline found - generating report without comparison"
          fi

          python .github/scripts/generate-security-report.py \
            --reports-dir reports \
            --output-html security-report.html \
            --output-md security-summary.md \
            --output-baseline security-baseline.json \
            $BASELINE_ARG \
            --branch "${{ github.ref_name }}" \
            --commit "${{ github.sha }}" \
            --repo "${{ github.repository }}"

      - name: Post summary to GitHub
        if: always()
        run: cat security-summary.md >> $GITHUB_STEP_SUMMARY

      - name: Upload security report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: consolidated-security-report
          path: |
            security-report.html
            security-summary.md
            security-baseline.json
            reports/
          retention-days: 90

      - name: Upload baseline for future comparisons
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-baseline
          path: security-baseline.json
          retention-days: 90

  # ===========================================================================
  # LAYER 8 ‚Äî Security Summary (push only)
  # ===========================================================================

  security-summary:
    name: Security Summary
    needs:
      - security-report
      - semgrep
      - python-sast
      - secret-scan
      - python-deps
      - js-deps
      - iac-scan
      - license-check
      - sbom
      - scan-app-image
      - scan-rec-image
      - container-sbom
      - dast-zap
      - dast-api
      - e2e-tests
    if: always() && github.event_name == 'push'
    runs-on: ubuntu-latest
    steps:
      - name: Generate security summary
        run: |
          echo "# DevSecOps Pipeline Security Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** \`${{ github.ref_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Static Analysis" >> $GITHUB_STEP_SUMMARY
          echo "- Semgrep SAST: ${{ needs.semgrep.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Python SAST (Bandit): ${{ needs.python-sast.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Secret Scan (Trufflehog): ${{ needs.secret-scan.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Software Composition Analysis" >> $GITHUB_STEP_SUMMARY
          echo "- Python SCA (pip-audit): ${{ needs.python-deps.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- JS SCA (npm audit): ${{ needs.js-deps.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Infrastructure & Compliance" >> $GITHUB_STEP_SUMMARY
          echo "- IaC Scan (Checkov): ${{ needs.iac-scan.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- License Compliance: ${{ needs.license-check.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- SBOM Generation: ${{ needs.sbom.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Container Security" >> $GITHUB_STEP_SUMMARY
          echo "- App Image Scan: ${{ needs.scan-app-image.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Rec Image Scan: ${{ needs.scan-rec-image.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Container SBOM: ${{ needs.container-sbom.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Dynamic Testing" >> $GITHUB_STEP_SUMMARY
          echo "- ZAP Full Scan: ${{ needs.dast-zap.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- ZAP API Scan: ${{ needs.dast-api.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Functional Testing" >> $GITHUB_STEP_SUMMARY
          echo "- E2E Selenium Tests: ${{ needs.e2e-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Report" >> $GITHUB_STEP_SUMMARY
          echo "- Consolidated Report: ${{ needs.security-report.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Download security reports from the Artifacts section below." >> $GITHUB_STEP_SUMMARY